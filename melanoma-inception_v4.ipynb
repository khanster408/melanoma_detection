{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import sys; sys.argv=['']; del sys\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from glob import glob \n",
    "from PIL import Image\n",
    "Image.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV4(\n",
      "  (features): Sequential(\n",
      "    (0): BasicConv2d(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicConv2d(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BasicConv2d(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Mixed_3a(\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv): BasicConv2d(\n",
      "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Mixed_4a(\n",
      "      (branch0): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicConv2d(\n",
      "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Mixed_5a(\n",
      "      (conv): BasicConv2d(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (6): Inception_A(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Inception_A(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): Inception_A(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): Inception_A(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): Reduction_A(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (11): Inception_B(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicConv2d(\n",
      "          (conv): Conv2d(224, 224, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): Inception_B(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicConv2d(\n",
      "          (conv): Conv2d(224, 224, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Inception_B(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicConv2d(\n",
      "          (conv): Conv2d(224, 224, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Inception_B(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicConv2d(\n",
      "          (conv): Conv2d(224, 224, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): Inception_B(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicConv2d(\n",
      "          (conv): Conv2d(224, 224, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Inception_B(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicConv2d(\n",
      "          (conv): Conv2d(224, 224, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): Inception_B(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1024, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicConv2d(\n",
      "          (conv): Conv2d(224, 224, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicConv2d(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): Reduction_B(\n",
      "      (branch0): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch1): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (conv): Conv2d(256, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicConv2d(\n",
      "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (19): Inception_C(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1_0): BasicConv2d(\n",
      "        (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1_1a): BasicConv2d(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1_1b): BasicConv2d(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_0): BasicConv2d(\n",
      "        (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_1): BasicConv2d(\n",
      "        (conv): Conv2d(384, 448, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_2): BasicConv2d(\n",
      "        (conv): Conv2d(448, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_3a): BasicConv2d(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_3b): BasicConv2d(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (20): Inception_C(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1_0): BasicConv2d(\n",
      "        (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1_1a): BasicConv2d(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1_1b): BasicConv2d(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_0): BasicConv2d(\n",
      "        (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_1): BasicConv2d(\n",
      "        (conv): Conv2d(384, 448, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_2): BasicConv2d(\n",
      "        (conv): Conv2d(448, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_3a): BasicConv2d(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_3b): BasicConv2d(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): Inception_C(\n",
      "      (branch0): BasicConv2d(\n",
      "        (conv): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1_0): BasicConv2d(\n",
      "        (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1_1a): BasicConv2d(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch1_1b): BasicConv2d(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_0): BasicConv2d(\n",
      "        (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_1): BasicConv2d(\n",
      "        (conv): Conv2d(384, 448, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_2): BasicConv2d(\n",
      "        (conv): Conv2d(448, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_3a): BasicConv2d(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2_3b): BasicConv2d(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1536, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.inception4.inceptionv4(pretrained='imagenet')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Melanoma detection training')\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0\n",
    "args.world_size = 1\n",
    "args.multiprocessing_distributed = False\n",
    "args.dist_url = 'http://localhost:3000'\n",
    "args.rank = 0\n",
    "args.gpu = None\n",
    "args.dist_backend = 'nccl'\n",
    "args.out_features = 3\n",
    "args.pretrained = True\n",
    "args.arch = 'inception4'\n",
    "args.workers = 4\n",
    "args.momentum = 0.9\n",
    "args.lr = 0.01\n",
    "args.weight_decay = 1e-4\n",
    "args.data = 'data'\n",
    "args.batch_size = 64\n",
    "args.start_epoch = 0\n",
    "args.epochs = 100\n",
    "args.save_model = 'inceptionv4-05112020-Adam.pth'\n",
    "args.evaluate = False\n",
    "args.print_freq = 2000\n",
    "args.print_freq_test = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)#.values()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 3))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 3))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq_test == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename=args.save_model):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'best_{}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 20))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def test(loaders, model, criterion, args):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(loaders)):\n",
    "        # move to GPU\n",
    "        if args.gpu is not None:\n",
    "            data = data.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(img_paths, model):\n",
    "    \n",
    "    model.eval()\n",
    "    pred_rank1 = []\n",
    "    pred_rank2 = []\n",
    "    transform = transforms.Compose([transforms.Resize(312),\n",
    "                                      transforms.CenterCrop(299),\n",
    "                                      transforms.ToTensor(),\n",
    "                                            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])])\n",
    "    img1 = Image.open(img_paths)\n",
    "    img = transform(img1)\n",
    "    prediction = model(img[None,:].cuda())\n",
    "    prediction = F.softmax(prediction, dim=1)\n",
    "    pred_rank1.append(float(prediction.data[0][0]))\n",
    "    pred_rank2.append(float(prediction.data[0][2]))\n",
    "    return pred_rank1, pred_rank2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    global best_acc1\n",
    "    args.gpu = gpu\n",
    "    if args.distributed:\n",
    "        if args.multiprocessing_distributed:\n",
    "            # For multiprocessing distributed training, rank needs to be the\n",
    "            # global rank among all the processes\n",
    "            args.rank = args.rank * ngpus_per_node + gpu\n",
    "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "                                world_size=args.world_size, rank=args.rank)\n",
    "    if args.pretrained:\n",
    "        print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "        model = models.__dict__[args.arch].inceptionv4(pretrained='imagenet')\n",
    "        \n",
    "    else:\n",
    "        print(\"=> creating model '{}'\".format(args.arch))\n",
    "        model = models.__dict__[args.arch].inceptionv4()\n",
    "    \n",
    "#     for params in model.features.parameters():\n",
    "#         params.requires_grad = False\n",
    "\n",
    "    \n",
    "    model.last_linear.out_features = args.out_features\n",
    "#     nn.Sequential(OrderedDict([('fc1', nn.Linear(2048, 512)),\n",
    "#                                          ('relu', nn.ReLU()),\n",
    "#                                          ('dropout', nn.Dropout(0.3)),\n",
    "#                                          ('fc2', nn.Linear(512, 3)), \n",
    "#                                          ('output', nn.Softmax(dim=1))]))#\n",
    "    \n",
    "    if args.distributed:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if args.gpu is not None:\n",
    "            torch.cuda.set_device(args.gpu)\n",
    "            model.cuda(args.gpu)\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "            args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "        else:\n",
    "            model.cuda()\n",
    "            # DistributedDataParallel will divide and allocate batch_size to all\n",
    "            # available GPUs if device_ids are not set\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model = model.cuda(args.gpu)\n",
    "    else:\n",
    "        # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "        if args.arch.startswith('alexnet') or args.arch.startswith('vgg'):\n",
    "            model.features = torch.nn.DataParallel(model.features)\n",
    "            model.cuda()\n",
    "        else:\n",
    "            model = torch.nn.DataParallel(model).cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    traindir = os.path.join(args.data, 'train')\n",
    "    valdir = os.path.join(args.data, 'valid')\n",
    "    testdir = os.path.join(args.data, 'test')\n",
    "    \n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.RandomResizedCrop(299),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    \n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(testdir, transforms.Compose([\n",
    "            transforms.Resize(312),\n",
    "            transforms.CenterCrop(299),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, transforms.Compose([\n",
    "            transforms.Resize(312),\n",
    "            transforms.CenterCrop(299),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "    \n",
    "    if args.evaluate:\n",
    "        validate(val_loader, model, criterion, args)\n",
    "        return\n",
    "    \n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        acc1 = validate(val_loader, model, criterion, args)\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "        if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "                and args.rank % ngpus_per_node == 0):\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_acc1': best_acc1,\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, is_best)\n",
    "            \n",
    "    test(test_loader, model, criterion, args)\n",
    "    \n",
    "    img_path = np.array(glob(\"data/test/*/*\"))\n",
    "    \n",
    "    \n",
    "    with open('results_inception4.csv', 'w', newline='') as csvfile:\n",
    "        doc = csv.writer(csvfile)\n",
    "        doc.writerow(['Id', 'task_1', 'task_2'])\n",
    "        for i in tqdm(range(len(img_path))):\n",
    "            pred = predict(img_path[i], model)\n",
    "            #print(pred[0][0])\n",
    "            doc.writerow([img_path[i], pred[0][0], pred[1][0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():   \n",
    "    \n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    print(ngpus_per_node)\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "    \n",
    "    if args.multiprocessing_distributed:\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, ))\n",
    "    else:\n",
    "        main_worker(args.gpu, ngpus_per_node, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "=> using pre-trained model 'inception4'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\cuda\\nccl.py:24: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 0/32]\tTime 40.124 (40.124)\tData 23.862 (23.862)\tLoss 7.2449e+00 (7.2449e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/3]\tTime 27.792 (27.792)\tLoss 9.5263e-01 (9.5263e-01)\tAcc@1  53.12 ( 53.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 52.000 Acc@5 100.000\n",
      "Epoch: [1][ 0/32]\tTime 30.427 (30.427)\tData 28.290 (28.290)\tLoss 7.9030e-01 (7.9030e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.707 (27.707)\tLoss 8.4103e-01 (8.4103e-01)\tAcc@1  57.81 ( 57.81)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 58.000 Acc@5 100.000\n",
      "Epoch: [2][ 0/32]\tTime 30.228 (30.228)\tData 27.988 (27.988)\tLoss 7.7671e-01 (7.7671e-01)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.693 (27.693)\tLoss 9.0806e-01 (9.0806e-01)\tAcc@1  56.25 ( 56.25)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 61.333 Acc@5 100.000\n",
      "Epoch: [3][ 0/32]\tTime 32.671 (32.671)\tData 30.499 (30.499)\tLoss 6.3289e-01 (6.3289e-01)\tAcc@1  67.19 ( 67.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.886 (28.886)\tLoss 9.8739e-01 (9.8739e-01)\tAcc@1  62.50 ( 62.50)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 74.667 Acc@5 100.000\n",
      "Epoch: [4][ 0/32]\tTime 27.624 (27.624)\tData 25.442 (25.442)\tLoss 5.8204e-01 (5.8204e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.739 (27.739)\tLoss 9.3278e-01 (9.3278e-01)\tAcc@1  64.06 ( 64.06)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 66.667 Acc@5 100.000\n",
      "Epoch: [5][ 0/32]\tTime 26.048 (26.048)\tData 23.842 (23.842)\tLoss 6.0645e-01 (6.0645e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.748 (27.748)\tLoss 7.0316e-01 (7.0316e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 76.000 Acc@5 100.000\n",
      "Epoch: [6][ 0/32]\tTime 28.082 (28.082)\tData 25.883 (25.883)\tLoss 4.8129e-01 (4.8129e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.706 (27.706)\tLoss 6.1629e-01 (6.1629e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 73.333 Acc@5 100.000\n",
      "Epoch: [7][ 0/32]\tTime 30.625 (30.625)\tData 28.490 (28.490)\tLoss 4.6554e-01 (4.6554e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.719 (27.719)\tLoss 9.3832e-01 (9.3832e-01)\tAcc@1  60.94 ( 60.94)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 73.333 Acc@5 100.000\n",
      "Epoch: [8][ 0/32]\tTime 24.634 (24.634)\tData 22.489 (22.489)\tLoss 4.4845e-01 (4.4845e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.704 (27.704)\tLoss 1.0083e+00 (1.0083e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 75.333 Acc@5 100.000\n",
      "Epoch: [9][ 0/32]\tTime 35.904 (35.904)\tData 33.727 (33.727)\tLoss 3.3377e-01 (3.3377e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 30.279 (30.279)\tLoss 4.7549e-01 (4.7549e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 77.333 Acc@5 100.000\n",
      "Epoch: [10][ 0/32]\tTime 26.861 (26.861)\tData 24.661 (24.661)\tLoss 4.3856e-01 (4.3856e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.602 (27.602)\tLoss 7.8061e-01 (7.8061e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.000 Acc@5 100.000\n",
      "Epoch: [11][ 0/32]\tTime 30.170 (30.170)\tData 27.934 (27.934)\tLoss 3.6946e-01 (3.6946e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.862 (27.862)\tLoss 6.4545e-01 (6.4545e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 79.333 Acc@5 100.000\n",
      "Epoch: [12][ 0/32]\tTime 33.138 (33.138)\tData 30.975 (30.975)\tLoss 4.9758e-01 (4.9758e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 31.281 (31.281)\tLoss 8.4186e-01 (8.4186e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [13][ 0/32]\tTime 29.280 (29.280)\tData 27.176 (27.176)\tLoss 4.1065e-01 (4.1065e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.696 (27.696)\tLoss 6.7323e-01 (6.7323e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [14][ 0/32]\tTime 36.595 (36.595)\tData 34.434 (34.434)\tLoss 3.2022e-01 (3.2022e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 30.078 (30.078)\tLoss 4.7651e-01 (4.7651e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [15][ 0/32]\tTime 34.714 (34.714)\tData 32.539 (32.539)\tLoss 2.2054e-01 (2.2054e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 29.224 (29.224)\tLoss 8.4888e-01 (8.4888e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 84.000 Acc@5 100.000\n",
      "Epoch: [16][ 0/32]\tTime 29.549 (29.549)\tData 27.320 (27.320)\tLoss 2.8582e-01 (2.8582e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.990 (27.990)\tLoss 9.3644e-01 (9.3644e-01)\tAcc@1  67.19 ( 67.19)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 76.000 Acc@5 100.000\n",
      "Epoch: [17][ 0/32]\tTime 25.995 (25.995)\tData 23.892 (23.892)\tLoss 3.0525e-01 (3.0525e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.981 (27.981)\tLoss 8.3137e-01 (8.3137e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.000 Acc@5 100.000\n",
      "Epoch: [18][ 0/32]\tTime 28.625 (28.625)\tData 26.508 (26.508)\tLoss 3.3173e-01 (3.3173e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.814 (27.814)\tLoss 1.2152e+00 (1.2152e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [19][ 0/32]\tTime 28.238 (28.238)\tData 26.034 (26.034)\tLoss 2.1011e-01 (2.1011e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.964 (27.964)\tLoss 1.0355e+00 (1.0355e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 83.333 Acc@5 100.000\n",
      "Epoch: [20][ 0/32]\tTime 24.056 (24.056)\tData 21.861 (21.861)\tLoss 1.3534e-01 (1.3534e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.839 (27.839)\tLoss 1.0628e+00 (1.0628e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 84.000 Acc@5 100.000\n",
      "Epoch: [21][ 0/32]\tTime 32.660 (32.660)\tData 30.381 (30.381)\tLoss 3.9787e-01 (3.9787e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.813 (27.813)\tLoss 9.8252e-01 (9.8252e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [22][ 0/32]\tTime 30.711 (30.711)\tData 28.603 (28.603)\tLoss 1.6109e-01 (1.6109e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.981 (27.981)\tLoss 1.0488e+00 (1.0488e+00)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [23][ 0/32]\tTime 27.538 (27.538)\tData 25.429 (25.429)\tLoss 2.2148e-01 (2.2148e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.982 (27.982)\tLoss 1.0339e+00 (1.0339e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [24][ 0/32]\tTime 32.891 (32.891)\tData 30.716 (30.716)\tLoss 1.9811e-01 (1.9811e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.874 (27.874)\tLoss 9.6520e-01 (9.6520e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [25][ 0/32]\tTime 24.751 (24.751)\tData 22.564 (22.564)\tLoss 1.8663e-01 (1.8663e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.906 (27.906)\tLoss 1.0054e+00 (1.0054e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [26][ 0/32]\tTime 33.084 (33.084)\tData 30.941 (30.941)\tLoss 1.1492e-01 (1.1492e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.177 (28.177)\tLoss 1.0240e+00 (1.0240e+00)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [27][ 0/32]\tTime 29.751 (29.751)\tData 27.557 (27.557)\tLoss 1.0618e-01 (1.0618e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.146 (28.146)\tLoss 9.8249e-01 (9.8249e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [28][ 0/32]\tTime 31.903 (31.903)\tData 29.739 (29.739)\tLoss 8.4249e-02 (8.4249e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.180 (28.180)\tLoss 9.3793e-01 (9.3793e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [29][ 0/32]\tTime 32.588 (32.588)\tData 30.400 (30.400)\tLoss 1.8624e-01 (1.8624e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.964 (27.964)\tLoss 8.9954e-01 (8.9954e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 89.333 Acc@5 100.000\n",
      "Epoch: [30][ 0/32]\tTime 24.384 (24.384)\tData 22.189 (22.189)\tLoss 1.8085e-01 (1.8085e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/3]\tTime 27.621 (27.621)\tLoss 9.1695e-01 (9.1695e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 89.333 Acc@5 100.000\n",
      "Epoch: [31][ 0/32]\tTime 26.862 (26.862)\tData 24.630 (24.630)\tLoss 1.9541e-01 (1.9541e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.055 (28.055)\tLoss 9.8962e-01 (9.8962e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [32][ 0/32]\tTime 32.921 (32.921)\tData 30.757 (30.757)\tLoss 1.6373e-01 (1.6373e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.731 (27.731)\tLoss 9.4040e-01 (9.4040e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [33][ 0/32]\tTime 32.497 (32.497)\tData 30.316 (30.316)\tLoss 1.2250e-01 (1.2250e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.951 (28.951)\tLoss 1.0200e+00 (1.0200e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [34][ 0/32]\tTime 26.749 (26.749)\tData 24.581 (24.581)\tLoss 2.4578e-01 (2.4578e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.984 (27.984)\tLoss 9.5941e-01 (9.5941e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [35][ 0/32]\tTime 25.932 (25.932)\tData 23.814 (23.814)\tLoss 1.8764e-01 (1.8764e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.873 (27.873)\tLoss 1.0777e+00 (1.0777e+00)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [36][ 0/32]\tTime 31.028 (31.028)\tData 28.791 (28.791)\tLoss 1.9041e-01 (1.9041e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.876 (27.876)\tLoss 9.6391e-01 (9.6391e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [37][ 0/32]\tTime 28.350 (28.350)\tData 26.132 (26.132)\tLoss 2.3205e-01 (2.3205e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.023 (28.023)\tLoss 9.3788e-01 (9.3788e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [38][ 0/32]\tTime 32.368 (32.368)\tData 30.256 (30.256)\tLoss 7.9606e-02 (7.9606e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.326 (28.326)\tLoss 9.5752e-01 (9.5752e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 90.000 Acc@5 100.000\n",
      "Epoch: [39][ 0/32]\tTime 26.125 (26.125)\tData 24.021 (24.021)\tLoss 8.2430e-02 (8.2430e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.244 (28.244)\tLoss 1.0413e+00 (1.0413e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 84.667 Acc@5 100.000\n",
      "Epoch: [40][ 0/32]\tTime 28.717 (28.717)\tData 26.494 (26.494)\tLoss 1.6319e-01 (1.6319e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 29.196 (29.196)\tLoss 1.0010e+00 (1.0010e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 84.667 Acc@5 100.000\n",
      "Epoch: [41][ 0/32]\tTime 30.862 (30.862)\tData 28.702 (28.702)\tLoss 2.2874e-01 (2.2874e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.833 (27.833)\tLoss 9.8587e-01 (9.8587e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.000 Acc@5 100.000\n",
      "Epoch: [42][ 0/32]\tTime 28.698 (28.698)\tData 26.596 (26.596)\tLoss 1.0367e-01 (1.0367e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.968 (27.968)\tLoss 9.5723e-01 (9.5723e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [43][ 0/32]\tTime 32.029 (32.029)\tData 29.918 (29.918)\tLoss 7.2381e-02 (7.2381e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.996 (27.996)\tLoss 9.1125e-01 (9.1125e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [44][ 0/32]\tTime 23.963 (23.963)\tData 21.752 (21.752)\tLoss 9.6330e-02 (9.6330e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.888 (27.888)\tLoss 1.0124e+00 (1.0124e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [45][ 0/32]\tTime 29.760 (29.760)\tData 27.575 (27.575)\tLoss 1.1211e-01 (1.1211e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.928 (27.928)\tLoss 9.0629e-01 (9.0629e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [46][ 0/32]\tTime 29.092 (29.092)\tData 26.862 (26.862)\tLoss 1.1631e-01 (1.1631e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.946 (27.946)\tLoss 9.3720e-01 (9.3720e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [47][ 0/32]\tTime 26.225 (26.225)\tData 24.025 (24.025)\tLoss 8.8050e-02 (8.8050e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.905 (27.905)\tLoss 8.7095e-01 (8.7095e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [48][ 0/32]\tTime 30.350 (30.350)\tData 28.236 (28.236)\tLoss 2.7396e-01 (2.7396e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.895 (27.895)\tLoss 9.3539e-01 (9.3539e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [49][ 0/32]\tTime 25.967 (25.967)\tData 23.862 (23.862)\tLoss 1.4666e-01 (1.4666e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 29.531 (29.531)\tLoss 1.0846e+00 (1.0846e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [50][ 0/32]\tTime 30.160 (30.160)\tData 27.933 (27.933)\tLoss 8.3515e-02 (8.3515e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 30.259 (30.259)\tLoss 1.0559e+00 (1.0559e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 84.667 Acc@5 100.000\n",
      "Epoch: [51][ 0/32]\tTime 35.690 (35.690)\tData 33.506 (33.506)\tLoss 1.2403e-01 (1.2403e-01)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.891 (27.891)\tLoss 9.9113e-01 (9.9113e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [52][ 0/32]\tTime 33.375 (33.375)\tData 31.261 (31.261)\tLoss 1.4066e-01 (1.4066e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.839 (27.839)\tLoss 8.6062e-01 (8.6062e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [53][ 0/32]\tTime 32.097 (32.097)\tData 29.904 (29.904)\tLoss 9.2580e-02 (9.2580e-02)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.037 (28.037)\tLoss 1.0404e+00 (1.0404e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [54][ 0/32]\tTime 30.911 (30.911)\tData 28.706 (28.706)\tLoss 1.3423e-01 (1.3423e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.905 (27.905)\tLoss 9.5015e-01 (9.5015e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [55][ 0/32]\tTime 28.264 (28.264)\tData 26.060 (26.060)\tLoss 1.4215e-01 (1.4215e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.916 (27.916)\tLoss 9.8534e-01 (9.8534e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [56][ 0/32]\tTime 27.745 (27.745)\tData 25.589 (25.589)\tLoss 1.0367e-01 (1.0367e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.781 (27.781)\tLoss 9.4081e-01 (9.4081e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [57][ 0/32]\tTime 30.833 (30.833)\tData 28.630 (28.630)\tLoss 1.1150e-01 (1.1150e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.911 (27.911)\tLoss 1.1920e+00 (1.1920e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 83.333 Acc@5 100.000\n",
      "Epoch: [58][ 0/32]\tTime 33.555 (33.555)\tData 31.358 (31.358)\tLoss 9.8046e-02 (9.8046e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.003 (28.003)\tLoss 1.0598e+00 (1.0598e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 84.667 Acc@5 100.000\n",
      "Epoch: [59][ 0/32]\tTime 33.798 (33.798)\tData 31.585 (31.585)\tLoss 1.5806e-01 (1.5806e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.814 (27.814)\tLoss 9.7872e-01 (9.7872e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [60][ 0/32]\tTime 28.339 (28.339)\tData 26.210 (26.210)\tLoss 6.9274e-02 (6.9274e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.890 (27.890)\tLoss 9.5718e-01 (9.5718e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [61][ 0/32]\tTime 27.609 (27.609)\tData 25.460 (25.460)\tLoss 1.5083e-01 (1.5083e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 30.919 (30.919)\tLoss 9.9080e-01 (9.9080e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [62][ 0/32]\tTime 30.269 (30.269)\tData 28.163 (28.163)\tLoss 6.6879e-02 (6.6879e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.972 (27.972)\tLoss 1.0949e+00 (1.0949e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [63][ 0/32]\tTime 33.477 (33.477)\tData 31.301 (31.301)\tLoss 1.7147e-01 (1.7147e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.919 (27.919)\tLoss 1.0843e+00 (1.0843e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 84.667 Acc@5 100.000\n",
      "Epoch: [64][ 0/32]\tTime 31.068 (31.068)\tData 28.870 (28.870)\tLoss 2.4943e-01 (2.4943e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.921 (27.921)\tLoss 1.0108e+00 (1.0108e+00)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [65][ 0/32]\tTime 31.148 (31.148)\tData 28.937 (28.937)\tLoss 1.2611e-01 (1.2611e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.984 (27.984)\tLoss 9.9048e-01 (9.9048e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [66][ 0/32]\tTime 30.525 (30.525)\tData 28.372 (28.372)\tLoss 6.5656e-02 (6.5656e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.901 (27.901)\tLoss 9.7272e-01 (9.7272e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [67][ 0/32]\tTime 34.361 (34.361)\tData 32.196 (32.196)\tLoss 1.4432e-01 (1.4432e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.728 (27.728)\tLoss 1.0321e+00 (1.0321e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [68][ 0/32]\tTime 25.161 (25.161)\tData 23.057 (23.057)\tLoss 1.5609e-01 (1.5609e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.660 (27.660)\tLoss 9.8930e-01 (9.8930e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [69][ 0/32]\tTime 28.541 (28.541)\tData 26.324 (26.324)\tLoss 2.1300e-01 (2.1300e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.734 (27.734)\tLoss 1.0396e+00 (1.0396e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [70][ 0/32]\tTime 28.971 (28.971)\tData 26.749 (26.749)\tLoss 1.2382e-01 (1.2382e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.279 (28.279)\tLoss 9.7085e-01 (9.7085e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [71][ 0/32]\tTime 28.570 (28.570)\tData 26.289 (26.289)\tLoss 1.6882e-01 (1.6882e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 29.865 (29.865)\tLoss 9.4822e-01 (9.4822e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [72][ 0/32]\tTime 32.060 (32.060)\tData 29.878 (29.878)\tLoss 1.0907e-01 (1.0907e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.804 (28.804)\tLoss 1.0279e+00 (1.0279e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.000 Acc@5 100.000\n",
      "Epoch: [73][ 0/32]\tTime 30.177 (30.177)\tData 27.968 (27.968)\tLoss 8.6747e-02 (8.6747e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.605 (27.605)\tLoss 9.6060e-01 (9.6060e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [74][ 0/32]\tTime 31.222 (31.222)\tData 28.982 (28.982)\tLoss 1.6800e-01 (1.6800e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.664 (27.664)\tLoss 1.0281e+00 (1.0281e+00)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [75][ 0/32]\tTime 28.865 (28.865)\tData 26.683 (26.683)\tLoss 8.3235e-02 (8.3235e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 30.297 (30.297)\tLoss 9.3913e-01 (9.3913e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [76][ 0/32]\tTime 32.972 (32.972)\tData 30.722 (30.722)\tLoss 1.6481e-01 (1.6481e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.643 (27.643)\tLoss 9.2007e-01 (9.2007e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [77][ 0/32]\tTime 31.700 (31.700)\tData 29.582 (29.582)\tLoss 8.2986e-02 (8.2986e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.704 (27.704)\tLoss 1.0395e+00 (1.0395e+00)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [78][ 0/32]\tTime 26.888 (26.888)\tData 24.691 (24.691)\tLoss 9.2797e-02 (9.2797e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.730 (27.730)\tLoss 1.0097e+00 (1.0097e+00)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [79][ 0/32]\tTime 28.167 (28.167)\tData 26.046 (26.046)\tLoss 1.0318e-01 (1.0318e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.769 (27.769)\tLoss 1.0244e+00 (1.0244e+00)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [80][ 0/32]\tTime 27.434 (27.434)\tData 25.322 (25.322)\tLoss 8.5230e-02 (8.5230e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.761 (27.761)\tLoss 1.0183e+00 (1.0183e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.000 Acc@5 100.000\n",
      "Epoch: [81][ 0/32]\tTime 27.433 (27.433)\tData 25.286 (25.286)\tLoss 1.8556e-01 (1.8556e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.660 (27.660)\tLoss 9.4625e-01 (9.4625e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [82][ 0/32]\tTime 31.105 (31.105)\tData 28.894 (28.894)\tLoss 8.2772e-02 (8.2772e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.716 (27.716)\tLoss 9.8728e-01 (9.8728e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 87.333 Acc@5 100.000\n",
      "Epoch: [83][ 0/32]\tTime 32.161 (32.161)\tData 30.063 (30.063)\tLoss 1.4518e-01 (1.4518e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.350 (28.350)\tLoss 1.0897e+00 (1.0897e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.000 Acc@5 100.000\n",
      "Epoch: [84][ 0/32]\tTime 30.520 (30.520)\tData 28.397 (28.397)\tLoss 1.1505e-01 (1.1505e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.867 (27.867)\tLoss 1.0345e+00 (1.0345e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [85][ 0/32]\tTime 29.599 (29.599)\tData 27.496 (27.496)\tLoss 1.5323e-01 (1.5323e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.948 (27.948)\tLoss 1.0254e+00 (1.0254e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.000 Acc@5 100.000\n",
      "Epoch: [86][ 0/32]\tTime 28.616 (28.616)\tData 26.347 (26.347)\tLoss 2.1350e-01 (2.1350e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 29.726 (29.726)\tLoss 1.0234e+00 (1.0234e+00)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [87][ 0/32]\tTime 29.901 (29.901)\tData 27.724 (27.724)\tLoss 2.4972e-01 (2.4972e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.770 (28.770)\tLoss 8.9304e-01 (8.9304e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 89.333 Acc@5 100.000\n",
      "Epoch: [88][ 0/32]\tTime 30.249 (30.249)\tData 28.117 (28.117)\tLoss 6.0880e-02 (6.0880e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.839 (27.839)\tLoss 9.3244e-01 (9.3244e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [89][ 0/32]\tTime 28.447 (28.447)\tData 26.318 (26.318)\tLoss 1.9746e-01 (1.9746e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.358 (28.358)\tLoss 1.0321e+00 (1.0321e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [90][ 0/32]\tTime 34.338 (34.338)\tData 32.221 (32.221)\tLoss 9.3126e-02 (9.3126e-02)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.290 (28.290)\tLoss 9.9699e-01 (9.9699e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [91][ 0/32]\tTime 25.883 (25.883)\tData 23.715 (23.715)\tLoss 8.7330e-02 (8.7330e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/3]\tTime 27.980 (27.980)\tLoss 1.0629e+00 (1.0629e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 84.667 Acc@5 100.000\n",
      "Epoch: [92][ 0/32]\tTime 29.191 (29.191)\tData 26.997 (26.997)\tLoss 1.2279e-01 (1.2279e-01)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.041 (28.041)\tLoss 9.2504e-01 (9.2504e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.667 Acc@5 100.000\n",
      "Epoch: [93][ 0/32]\tTime 31.084 (31.084)\tData 28.897 (28.897)\tLoss 1.0302e-01 (1.0302e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.835 (27.835)\tLoss 9.8631e-01 (9.8631e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n",
      "Epoch: [94][ 0/32]\tTime 31.199 (31.199)\tData 29.002 (29.002)\tLoss 1.6032e-01 (1.6032e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.924 (27.924)\tLoss 1.0200e+00 (1.0200e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [95][ 0/32]\tTime 32.055 (32.055)\tData 29.849 (29.849)\tLoss 8.9830e-02 (8.9830e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 29.020 (29.020)\tLoss 1.0235e+00 (1.0235e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 85.333 Acc@5 100.000\n",
      "Epoch: [96][ 0/32]\tTime 33.422 (33.422)\tData 31.264 (31.264)\tLoss 7.6926e-02 (7.6926e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.805 (27.805)\tLoss 8.8838e-01 (8.8838e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 89.333 Acc@5 100.000\n",
      "Epoch: [97][ 0/32]\tTime 30.774 (30.774)\tData 28.594 (28.594)\tLoss 1.7064e-01 (1.7064e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.860 (28.860)\tLoss 9.7648e-01 (9.7648e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.667 Acc@5 100.000\n",
      "Epoch: [98][ 0/32]\tTime 32.145 (32.145)\tData 30.027 (30.027)\tLoss 6.7714e-02 (6.7714e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.118 (28.118)\tLoss 1.0274e+00 (1.0274e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 86.000 Acc@5 100.000\n",
      "Epoch: [99][ 0/32]\tTime 30.342 (30.342)\tData 28.110 (28.110)\tLoss 2.9890e-01 (2.9890e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 31.057 (31.057)\tLoss 9.7502e-01 (9.7502e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 88.000 Acc@5 100.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:54, 54.17s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torchvision\\models\\inception4.py\", line 309, in forward\n    x = self.features(input)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 100, in forward\n    input = module(input)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torchvision\\models\\inception4.py\", line 260, in forward\n    out = torch.cat((x0, x1, x2, x3), 1)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 11.18 GiB total capacity; 10.76 GiB already allocated; 12.19 MiB free; 10.87 GiB reserved in total by PyTorch)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-7f4213fd19e2>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_worker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mngpus_per_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngpus_per_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mmain_worker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngpus_per_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-47bee70fe1ca>\u001b[0m in \u001b[0;36mmain_worker\u001b[1;34m(gpu, ngpus_per_node, args)\u001b[0m\n\u001b[0;32m    140\u001b[0m             }, is_best)\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/test/*/*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-8814e310a874>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(loaders, model, criterion, args)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;31m# calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[1;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[1;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[1;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torchvision\\models\\inception4.py\", line 309, in forward\n    x = self.features(input)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 100, in forward\n    input = module(input)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torchvision\\models\\inception4.py\", line 260, in forward\n    out = torch.cat((x0, x1, x2, x3), 1)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 11.18 GiB total capacity; 10.76 GiB already allocated; 12.19 MiB free; 10.87 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__[args.arch].inceptionv4(pretrained='imagenet')\n",
    "model.last_linear.out_features = args.out_features\n",
    "model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_load = torch.load('best_inceptionv4-05112020-Adam.pth')\n",
    "model.load_state_dict(m_load[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdir = os.path.join(args.data, 'test')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(testdir, transforms.Compose([\n",
    "            transforms.Resize(312),\n",
    "            transforms.CenterCrop(299),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=32, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [01:57,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.601656\n",
      "\n",
      "\n",
      "Test Accuracy: 82% (493/600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_loader, model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 600/600 [08:15<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "img_path = np.array(glob(\"data/test/*/*\"))\n",
    "    \n",
    "    \n",
    "with open('results_inception4.csv', 'w', newline='') as csvfile:\n",
    "    doc = csv.writer(csvfile)\n",
    "    doc.writerow(['Id', 'task_1', 'task_2'])\n",
    "    for i in tqdm(range(len(img_path))):\n",
    "        pred = predict(img_path[i], model)\n",
    "        #print(pred[0][0])\n",
    "        doc.writerow([img_path[i], pred[0][0], pred[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1 Score: 0.880\n",
      "Category 2 Score: 0.951\n",
      "Category 3 Score: 0.916\n"
     ]
    }
   ],
   "source": [
    "import get_results as results\n",
    "import pandas as pd\n",
    "\n",
    "y_true = pd.read_csv('ground_truth.csv')\n",
    "y_true = y_true[['task_1', 'task_2']].astype(float).to_numpy()\n",
    "\n",
    "#y_pred = pd.read_csv('sample_predictions.csv')\n",
    "y_pred = pd.read_csv('results_inception4.csv')\n",
    "y_pred = y_pred[['task_1', 'task_2']].astype(float).to_numpy()\n",
    "\n",
    "results.plot_roc_auc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
